<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LION ü¶Å Part IV - Results | Arshia Afzal </title> <meta name="author" content="Arshia Afzal"> <meta name="description" content="Comprehensive results of LION on Vision, MLM and LION variants"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9D&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://arshiaafzal.github.io/blog/2024/mamba2-part4-results/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "LION ü¶Å Part IV - Results",
            "description": "Comprehensive results of LION on Vision, MLM and LION variants",
            "published": "May 31, 2024",
            "authors": [
              
              {
                "author": "Arshia Afzal",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Writer of blogpost",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Elias Abad Rocamora",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Leyla Naz Candogan",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Pol Puigdemont Plana",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Writer of blogpost",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Francesco Tonin",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Yongtao Wu",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Volkan Cevher",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "All authors are with EPFL",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Arshia</span> Afzal </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>LION ü¶Å Part IV - Results</h1> <p>Comprehensive results of LION on Vision, MLM and LION variants</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#vision-results">Vision Results</a> </div> <ul> <li> <a href="#base-model-performance">Base Model Performance</a> </li> <li> <a href="#memory-efficiency">Memory Efficiency</a> </li> <li> <a href="#training-time-analysis">Training Time Analysis</a> </li> </ul> <div> <a href="#mlm-results">MLM Results</a> </div> <ul> <li> <a href="#bert-comparison">BERT Comparison</a> </li> </ul> <div> <a href="#lion-architecture-variants">LION Architecture Variants</a> </div> <ul> <li> <a href="#architecture-trade-offs">Architecture Trade-offs</a> </li> </ul> </nav> </d-contents> <ol> <li><a href="/blog/2025/mamba2-part1-model/">Part I - Full Linear Attention</a></li> <li><a href="/blog/2025/mamba2-part2-theory/">Part II - Bi-directional RNN</a></li> <li><a href="/blog/2025/mamba2-part3-algorithm/">Part III - Chunkwise Parallel from of LION</a></li> <li>Part IV - Results</li> </ol> <p>In this fourth part of our LION series, we will present and discuss a selection of experimental results across various domains, including vision tasks, masked language modeling (MLM), and different LION architectures. These results not only highlight LION‚Äôs versatility and efficiency across diverse applications but also serve as a preview of the comprehensive findings detailed in the full paper.</p> <h2 id="image-classification-performance-overview">Image Classification Performance Overview</h2> <h3 id="model-comparisons">Model Comparisons</h3> <p>We evaluated LION‚Äôs performance, efficiency, and training times against state-of-the-art SSMs and Transformers for image classification. The results demonstrate that LION achieves competitive performance while offering significant advantages in training speed and efficiency.</p> <table> <thead> <tr> <th>Model</th> <th>#Param</th> <th>Imagenet Top-1 Acc.</th> <th>Train. time</th> </tr> </thead> <tbody> <tr> <td>ViT</td> <td>86M</td> <td>$77.9$</td> <td>$\times 1$</td> </tr> <tr> <td>DeiT</td> <td>86M</td> <td>$\underline{81.8}$</td> <td>$\times 1$</td> </tr> <tr> <td>Hydra</td> <td>104M</td> <td>$81.0$</td> <td>$\times 2.51$</td> </tr> <tr> <td>Vim</td> <td>98M</td> <td>$\mathbf{81.9}$</td> <td>$\times 10.86$</td> </tr> <tr> <td>LION-üî•</td> <td>86M</td> <td>$74.7$</td> <td>$\mathbf{\times 0.73}$</td> </tr> <tr> <td>LION-D</td> <td>86M</td> <td>$77.8$</td> <td>$\times \underline{1.39}$</td> </tr> <tr> <td>$LION-D^{\natural}$</td> <td>86M</td> <td>$80.2$</td> <td>$\times 1.48$</td> </tr> <tr> <td>$LION-S$</td> <td>86M</td> <td>$76.3$</td> <td>$\times 1.46$</td> </tr> <tr> <td>$LION-S^{\natural}$</td> <td>86M</td> <td>$79.9$</td> <td>$\times 1.68$</td> </tr> </tbody> </table> <p>As shown in the table above, LION models achieve competitive performance with vision-specific SSMs like Vim, while being significantly faster during training. LION-D performs comparably to Vim and surpasses Hydra <d-cite key="hwang2025hydra"></d-cite>, while training approximately 7x faster than Vim <d-cite key="zhu2024vision"></d-cite>. Notably, LION-üî• demonstrates the highest training speed across all models, showing that training with full linear attention is significantly faster than chunkwise parallel training (used in Hydra) and considerably faster than the scan algorithm, even with optimized GPU kernels (as used in Vim).(LION-S^{\natural}) and (LION-D^{\natural}) modify the order of patches in an image to better capture the locality inherent in spatial patterns. By rearranging the patch sequence, these models enhance their understanding of local structures while still leveraging the efficiency of linear attention mechanisms similar to xLSTM <d-cite key="alkin2024vision"></d-cite>.</p> <h3 id="memory-efficiency">Memory Efficiency</h3> <p>The LION family demonstrates excellent memory efficiency across both vision and language tasks. Figure below shows inference memory usage with a batch size of 64 across different image resolutions, LION models maintain reasonable memory consumption even at high resolutions up to 2496 pixels, while adding minimal training overhead in BERT-style language modeling scenarios. In contrast, baseline models like ViT and DeiT run out of memory (OOM) at much lower resolutions, highlighting LION‚Äôs memory scaling capabilities regardless of the application domain.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fig1_plot.svg" sizes="95vw"></source> <img src="/assets/img/fig1_plot.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Memory Usage Comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Memory usage during inference across different architectures with batch size 64. LION models maintain reasonable memory consumption at high resolutions while other models run out of memory.</figcaption> </figure> </div> </div> <h3 id="training-time-analysis">Training Time Analysis</h3> <p>The LION family demonstrates remarkable training efficiency across both vision and language tasks. As shown in the table below, LION variants add minimal training overhead compared to standard Transformers, with some variants even training faster.</p> <table class="table-caption"> <thead> <tr> <th>Task</th> <th><span style="background-color: rgb(230, 255, 230); padding: 3px; color:black">LION-üî• </span></th> <th><span style="background-color: rgb(229, 204, 230); padding: 3px; color:black">LION-D </span></th> <th><span style="background-color: rgb(255, 233, 211) ; padding: 3px; color:black">LION-S </span></th> <th>Hydra</th> <th>Vim</th> </tr> </thead> <tbody> <tr> <td>Vision</td> <td>$\times 0.73$</td> <td>$\times 1.39$</td> <td>$\times 1.46$</td> <td>$\times 2.51$</td> <td>$\times 10.86$</td> </tr> <tr> <td>MLM</td> <td>$\times 0.95$</td> <td>$\times 1.10$</td> <td>$\times 1.32$</td> <td>$\times 3.13$</td> <td>‚úó</td> </tr> </tbody> </table> <p><em>Training Times (relative to Transformer) ‚Üì</em></p> <p>For vision tasks, LION-üî• achieves remarkable speed, training 27% faster than standard vision Transformers <d-cite key="dosovitskiy2020image"></d-cite>. Even the more complex LION variants maintain competitive training times, with LION-retnet and LION-S training only ~1.4x slower than Transformers. This is significantly better than competing approaches like Hydra (2.51x slower) and Vim (10.86x slower).</p> <p>In MLM tasks, the efficiency gains are even more pronounced. LION-üî• nearly matches Transformer training speed at just 0.95x, while LION-retnet adds only 10% overhead. Even LION-S remains efficient at 1.32x. All LION variants significantly outperform Hydra‚Äôs 3.13x slowdown, while Vim is not applicable to MLM tasks (marked as ‚úó).</p> <h2 id="mlm-results">MLM Results</h2> <p>For masked language modeling (MLM) tasks, we evaluated LION models against BERT <d-cite key="devlin2018bert"></d-cite> and Hydra on both MLM pretraining and GLUE benchmark finetuning. The results show that LION variants achieve competitive performance while maintaining excellent training efficiency.</p> <table class="table-caption"> <thead> <tr> <th>Model</th> <th>MLM Acc.</th> <th>GLUE</th> <th>Train. time</th> </tr> </thead> <tbody> <tr> <td>BERT</td> <td>$\underline{69.88}$</td> <td>$\mathbf{82.95}$</td> <td>$\times 1$</td> </tr> <tr> <td>Hydra</td> <td>$\mathbf{71.18}$</td> <td>$\underline{81.77}$</td> <td>$\times 3.13$</td> </tr> <tr> <td><span style="background-color: rgb(230, 255, 230); padding: 3px; color:black">LION-üî• </span></td> <td>$67.11$</td> <td>$80.76$</td> <td>$\times \mathbf{0.95}$</td> </tr> <tr> <td><span style="background-color: rgb(229, 204, 230); padding: 3px; color:black">LION-D </span></td> <td>$68.64$</td> <td>$81.34$</td> <td>$\times \underline{1.10}$</td> </tr> <tr> <td><span style="background-color: rgb(255, 233, 211) ; padding: 3px; color:black">LION-S </span></td> <td>$69.16$</td> <td>$81.58$</td> <td>$\times 1.32$</td> </tr> </tbody> </table> <p><em>C4 MLM and GLUE results for the LARGE scale ($334$M). For each dataset, the best and second best results are highlighted with bold and underline respectively.</em></p> <h2 id="lion-architecture-variants-and-trade-offs">LION Architecture Variants and Trade-offs</h2> <p>Let‚Äôs explore how different LION variants handle the trade-off between memory usage and inference speed. We‚Äôll look at three key approaches:</p> <ol> <li>Full Linear Attention - The standard approach using the full attention matrix</li> <li>Bidirectional RNN - Our memory-efficient RNN formulation</li> <li>LION Chunk - A balanced approach using chunked computation</li> </ol> <h3 id="memory-vs-speed-trade-offs">Memory vs Speed Trade-offs</h3> <p>The first plot below shows how these approaches compare in terms of memory efficiency and inference speed. The RNN approach proves to be the most memory-efficient, while full attention uses the most memory. LION chunk provides a nice middle ground - it uses less memory than full attention while actually achieving faster inference speeds than both alternatives. This makes it particularly attractive when you need to balance performance with resource constraints.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fig3_plot.svg" sizes="95vw"></source> <img src="/assets/img/fig3_plot.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Impact of Chunk Size" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Analysis of how chunk size affects model performance across different LION variants.</figcaption> </figure> </div> </div> <h3 id="detailed-performance-analysis">Detailed Performance Analysis</h3> <p>Looking more closely at the memory-time trade-off across different LION variants, we can see some interesting patterns. While RNN remains the most memory-efficient across all models, both chunking and full attention hit memory limits much sooner. The chunking approach matches or beats full attention‚Äôs inference speed for simpler variants like LION-RetNet. However, with more complex variants like LION-S, chunking is only faster at lower resolutions - at higher resolutions, the overhead from mask calculations starts to slow it down.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear_chunking.svg" sizes="95vw"></source> <img src="/assets/img/linear_chunking.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Linear Chunking Analysis" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Evaluation of linear chunking strategies and their impact on model efficiency.</figcaption> </figure> </div> </div> <h3 id="selective-chunking-results">Selective Chunking Results</h3> <p>The final analysis examines how different chunking strategies perform across sequence lengths. This helps inform which approach is best for different scenarios - chunking tends to be optimal for LION-üî• and LION-RetNet when memory allows, while RNN can be preferable for handling complex masks at high resolutions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/selective_chunking.svg" sizes="95vw"></source> <img src="/assets/img/selective_chunking.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Selective Chunking Analysis" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Performance comparison of selective chunking approaches across different sequence lengths.</figcaption> </figure> </div> </div> <h2 id="future-directions">Future Directions</h2> <ul> <li> <p><strong>Expanding LION‚Äôs Potential:</strong> Our experiments focused on three main mask choices, but LION has the potential to accelerate other Linear Transformer variants for bidirectional tasks.</p> </li> <li> <p><strong>Optimizing Chunkwise Parallelism:</strong> The chunkwise parallel implementation during inference was done in PyTorch, with room for optimization through GPU kernel programming to reduce I/O overhead and improve speed.</p> </li> <li> <p><strong>Stabilizing Hydra and Mamba with LION:</strong> Hydra (cite) and Mamba (cite) activations led to unstable training under full attention, suggesting LION could be used to stabilize these variants in the future.</p> </li> </ul> <h2 id="last-points">Last Points</h2> <p>We highly encourage the readers of this blog post to actually read our paper for way more details about the LION model and experimental setups.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/albert.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Arshia Afzal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>